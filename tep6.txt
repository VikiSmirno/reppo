
Этап 6. Машинное обучение и интерпретация


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# ML библиотеки
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from sklearn.linear_model import Ridge
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor

# Популярные библиотеки, которые могут отсутствовать
try:
    from lightgbm import LGBMRegressor
    LGBM_AVAILABLE = True
except ImportError:
    LGBM_AVAILABLE = False
    print("[WARNING] LightGBM не установлен. Модель будет пропущена.")

import optuna
import shap

# Отключаем лишний шум от Optuna
optuna.logging.set_verbosity(optuna.logging.WARNING)

def perform_ml_training_and_interpretation(df: pd.DataFrame, target_col: str, n_trials=20, test_size=0.2):
    """
    Универсальный пайплайн Этапа 6:
    1. Split данных.
    2. Байесовская оптимизация (Optuna) для Zoo моделей.
    3. Оценка качества (RMSE, R2).
    4. Интерпретация (SHAP).
    """
    
    print("="*60)
    print("ЭТАП 6: МАШИННОЕ ОБУЧЕНИЕ И ИНТЕРПРЕТАЦИЯ (XAI)")
    print("="*60)
    
    # 1. Подготовка данных
    X = df.drop(columns=[target_col])
    y = df[target_col]
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)
    print(f"Train shape: {X_train.shape}, Test shape: {X_test.shape}")
    
    # 2. Определение пространства поиска для моделей
    def objective(trial, model_name):
        """Внутренняя функция оптимизации для Optuna"""
        
        if model_name == 'Ridge':
            params = {
                'alpha': trial.suggest_float('alpha', 1e-3, 1e3, log=True),
                'solver': trial.suggest_categorical('solver', ['auto', 'svd', 'cholesky', 'lsqr'])
            }
            model = Ridge(**params)
            
        elif model_name == 'SVR':
            params = {
                'C': trial.suggest_float('C', 1e-2, 1e3, log=True),
                'epsilon': trial.suggest_float('epsilon', 0.01, 1.0),
                'kernel': trial.suggest_categorical('kernel', ['linear', 'rbf']) # poly убрал для скорости
            }
            model = SVR(**params)
            
        elif model_name == 'RandomForest':
            params = {
                'n_estimators': trial.suggest_int('n_estimators', 50, 300),
                'max_depth': trial.suggest_int('max_depth', 3, 20),
                'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),
                'n_jobs': -1,
                'random_state': 42
            }
            model = RandomForestRegressor(**params)
            
        elif model_name == 'LGBM' and LGBM_AVAILABLE:
            params = {
                'n_estimators': trial.suggest_int('n_estimators', 50, 500),
                'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True),
                'max_depth': trial.suggest_int('max_depth', 3, 15),
                'num_leaves': trial.suggest_int('num_leaves', 20, 100),
                'verbose': -1,
                'random_state': 42
            }
            model = LGBMRegressor(**params)
        else:
            return None

        # Кросс-валидация (3 фолда для скорости)
        # neg_mean_squared_error возвращает отрицательные значения, поэтому берем минус
        scores = cross_val_score(model, X_train, y_train, cv=3, scoring='neg_mean_squared_error')
        return -scores.mean()

    # Список моделей для перебора
    model_names = ['Ridge', 'SVR', 'RandomForest']
    if LGBM_AVAILABLE:
        model_names.append('LGBM')

    results_data = []
    best_models = {}

    print("\n[1] ЗАПУСК ОПТИМИЗАЦИИ ГИПЕРПАРАМЕТРОВ (OPTUNA)")
    
    for name in model_names:
        print(f"  -> Оптимизация {name} ({n_trials} итераций)...", end=" ")
        
        study = optuna.create_study(direction='minimize')
        study.optimize(lambda trial: objective(trial, name), n_trials=n_trials)
        
        print(f"Best CV MSE: {study.best_value:.4f}")
        
        # Обучаем финальную модель с лучшими параметрами на всем Train
        best_params = study.best_params
        
        if name == 'Ridge': model = Ridge(**best_params)
        elif name == 'SVR': model = SVR(**best_params)
        elif name == 'RandomForest': model = RandomForestRegressor(**best_params, n_jobs=-1, random_state=42)
        elif name == 'LGBM': model = LGBMRegressor(**best_params, verbose=-1, random_state=42)
        
        model.fit(X_train, y_train)
        best_models[name] = model
        
        # Предикт на тесте
        y_pred = model.predict(X_test)
        
        # Метрики
        r2 = r2_score(y_test, y_pred)
        rmse = np.sqrt(mean_squared_error(y_test, y_pred))
        mae = mean_absolute_error(y_test, y_pred)
        
        results_data.append({
            'Model': name,
            'R2': r2,
            'RMSE': rmse,
            'MAE': mae
        })

    # 3. Сводная таблица результатов
    results_df = pd.DataFrame(results_data).sort_values(by='RMSE', ascending=True)
    
    print("\n[2] РЕЗУЛЬТАТЫ (LEADERBOARD)")
    display(results_df) # Используйте print(results_df) вне Jupyter

    # Выбираем победителя
    best_model_name = results_df.iloc[0]['Model']
    best_model = best_models[best_model_name]
    print(f"\n>>> ПОБЕДИТЕЛЬ: {best_model_name}")

    # 4. Визуализация предсказаний
    print(f"\n[3] ВИЗУАЛИЗАЦИЯ ОШИБОК ({best_model_name})")
    
    y_pred_best = best_model.predict(X_test)
    
    plt.figure(figsize=(8, 6))
    plt.scatter(y_test, y_pred_best, alpha=0.5, color='blue', label='Предсказания')
    
    # Линия идеального предсказания
    min_val = min(y_test.min(), y_pred_best.min())
    max_val = max(y_test.max(), y_pred_best.max())
    plt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Идеал')
    
    plt.xlabel('Фактические значения')
    plt.ylabel('Предсказанные значения')
    plt.title(f'{best_model_name}: Fact vs Predict (R2={results_df.iloc[0]["R2"]:.3f})')
    plt.legend()
    plt.grid(True)
    plt.show()

    # 5. Интерпретация SHAP
    print(f"\n[4] ИНТЕРПРЕТАЦИЯ SHAP (Важность признаков)")
    
    try:
        # Для скорости берем подвыборку теста, если данных много
        shap_sample = X_test if len(X_test) < 500 else X_test.sample(500, random_state=42)
        
        explainer = None
        
        # Выбор объяснялки в зависимости от типа модели
        if best_model_name in ['RandomForest', 'LGBM']:
            explainer = shap.TreeExplainer(best_model)
            shap_values = explainer.shap_values(shap_sample)
        elif best_model_name == 'Ridge':
            explainer = shap.LinearExplainer(best_model, shap_sample)
            shap_values = explainer.shap_values(shap_sample)
        else:
            # Для SVR и других сложных моделей используем KernelExplainer (медленный)
            print("Используется KernelExplainer (это может занять время)...")
            explainer = shap.KernelExplainer(best_model.predict, shap_sample)
            shap_values = explainer.shap_values(shap_sample)

        plt.figure(figsize=(10, 6))
        plt.title(f"SHAP Summary Plot: {best_model_name}")
        shap.summary_plot(shap_values, shap_sample, show=True)
        
    except Exception as e:
        print(f"Ошибка при построении SHAP: {e}")
        print("Возможно, версия библиотеки несовместима или модель слишком специфична.")

    return best_model, results_df

# --- ПРИМЕР ИСПОЛЬЗОВАНИЯ ---
# final_model, metrics = perform_ml_training_and_interpretation(
#     df_ready_for_ml, 
#     target_col='Гармония Бессмертия', 
#     n_trials=15
# )