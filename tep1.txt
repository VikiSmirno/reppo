Универсальный скрипт для EDA и первичной гигиены

import pandas as pd
import numpy as np

def perform_eda_and_hygiene(df: pd.DataFrame, missing_markers=None, categorical_threshold=20):
    """
    Универсальная функция для 1-го этапа обработки данных.
    
    Параметры:
    df (pd.DataFrame): Исходный датафрейм.
    missing_markers (list): Список значений, которые считаются скрытыми пропусками (напр. '-', '?').
    categorical_threshold (int): Порог уникальных значений, чтобы считать колонку потенциально категориальной.
    """
    
    # Создаем копию, чтобы не менять исходный объект извне
    df_clean = df.copy()
    
    if missing_markers is None:
        missing_markers = ['-', 'Не определено', '?', '', 'nan', 'None', 'Null']

    print("="*50)
    print("ЭТАП 1: РАЗВЕДОЧНЫЙ АНАЛИЗ И ГИГИЕНА ДАННЫХ")
    print("="*50)

    # ---------------------------------------------------------
    # 1. Загрузка и аудит структуры
    # ---------------------------------------------------------
    print(f"\n[1] АУДИТ СТРУКТУРЫ")
    print(f"Размерность датасета: {df_clean.shape}")
    print("\nТипы данных (сводка):")
    print(df_clean.dtypes.value_counts())
    
    print("\nПервые 3 строки данных:")
    display(df_clean.head(3)) # Если запускаете не в Jupyter, замените на print

    # ---------------------------------------------------------
    # 2. Поиск скрытых пропусков
    # ---------------------------------------------------------
    print(f"\n[2] ПОИСК И ЗАМЕНА СКРЫТЫХ ПРОПУСКОВ")
    print(f"Список маркеров для замены на NaN: {missing_markers}")
    
    # Проходим только по строковым колонкам (object)
    object_cols = df_clean.select_dtypes(include=['object']).columns
    
    replaced_count = 0
    for col in object_cols:
        # Считаем, сколько таких значений есть в колонке перед заменой
        mask = df_clean[col].isin(missing_markers)
        if mask.sum() > 0:
            print(f"  -> Колонка '{col}': найдено {mask.sum()} скрытых пропусков.")
            df_clean[col] = df_clean[col].replace(missing_markers, np.nan)
            replaced_count += 1
            
    if replaced_count == 0:
        print("  Скрытые пропуски из списка не обнаружены.")

    # ---------------------------------------------------------
    # 3. Приведение типов (Object -> Float)
    # ---------------------------------------------------------
    print(f"\n[3] ПРИВЕДЕНИЕ ТИПОВ")
    # Попытка преобразовать все object колонки в числа
    # Если колонка содержит только цифры и NaNs, она станет float
    # Если содержит реальный текст, преобразование вызовет ошибку или создаст NaN (мы контролируем это)
    
    converted_cols = []
    for col in df_clean.select_dtypes(include=['object']).columns:
        # Пытаемся конвертировать в числа
        # errors='coerce' превратит нечисловые строки (которые мы могли пропустить в шаге 2) в NaN
        series_numeric = pd.to_numeric(df_clean[col], errors='coerce')
        
        # Проверка: если после конвертации количество NaN не стало критическим (например, не 100%),
        # и исходная колонка не состояла целиком из NaN, применяем изменение.
        # В данном контексте мы предполагаем, что если пользователь хочет "Forced conversion", 
        # то мы доверяем pd.to_numeric.
        
        # Сравним количество NaN до и после (чтобы не убить текстовые колонки типа "Имя")
        nan_before = df_clean[col].isna().sum()
        nan_after = series_numeric.isna().sum()
        
        # Эвристика: если количество пропусков выросло незначительно или колонка выглядит как числовая
        # (в данном случае применяем агрессивный подход, как в примере)
        if nan_after < len(df_clean): 
            # Если колонка действительно содержала числа (пусть и как строки), конвертируем
            # Но если это была колонка "Категория", где слова, она станет вся NaN.
            # Поэтому добавим проверку: конвертируем только если хотя бы одно значение удалось распознать как число
            # (исключая исходные NaN)
            if series_numeric.notna().sum() > 0:
                 df_clean[col] = series_numeric
                 converted_cols.append(col)

    if converted_cols:
        print(f"  Успешно преобразованы в числа: {converted_cols}")
    else:
        print("  Числовых колонок в формате строк не найдено.")

    # ---------------------------------------------------------
    # 4. Анализ кардинальности и рекомендации
    # ---------------------------------------------------------
    print(f"\n[4] АНАЛИЗ УНИКАЛЬНЫХ ЗНАЧЕНИЙ (КАРДИНАЛЬНОСТЬ)")
    
    categorical_candidates = []
    
    for col in df_clean.columns:
        unique_count = df_clean[col].nunique()
        dtype = df_clean[col].dtype
        
        # Если уникальных значений мало (меньше порога) ИЛИ это все еще тип object/string
        if unique_count <= categorical_threshold or dtype == 'object':
            unique_vals = df_clean[col].unique()
            # Ограничим вывод, если значений все же многовато для принта
            vals_to_print = unique_vals[:10] 
            ellipsis = "..." if len(unique_vals) > 10 else ""
            
            print(f"  Колонка '{col}' ({dtype}): {unique_count} уник. знач.")
            print(f"    Примеры: {vals_to_print} {ellipsis}")
            
            if dtype == 'object' and unique_count <= categorical_threshold:
                categorical_candidates.append(col)
                
    print("\n--- РЕКОМЕНДАЦИИ ПО КОДИРОВАНИЮ ---")
    if categorical_candidates:
        print(f"Обнаружены потенциальные категориальные признаки для кодирования: {categorical_candidates}")
        print("Рекомендуется создать mapping-словарь для порядковых (Ordinal) признаков")
        print("или использовать One-Hot/Label Encoding для номинальных.")
    else:
        print("Явных кандидатов на ручное кодирование (object с малой кардинальностью) не найдено.")

    print("\n" + "="*50)
    print("ЭТАП 1 ЗАВЕРШЕН")
    print("="*50)
    
    return df_clean

# --- ПРИМЕР ИСПОЛЬЗОВАНИЯ ---
# df = pd.read_csv('ваш_файл.csv')
# df_processed = perform_eda_and_hygiene(df)