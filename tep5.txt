Этап 5. Отбор признаков и масштабирование


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import RobustScaler
from sklearn.decomposition import PCA

def perform_feature_selection_and_scaling(df: pd.DataFrame, target_col: str = None, corr_threshold: float = 0.9):
    """
    Универсальный пайплайн Этапа 5:
    1. Удаление мультиколлинеарности.
    2. Robust Scaling.
    3. Анализ PCA (справочно).
    
    Возвращает:
    df_final (pd.DataFrame): Датасет с отобранными и отмасштабированными признаками (включая таргет).
    """
    
    print("="*60)
    print("ЭТАП 5: ОТБОР ПРИЗНАКОВ, МАСШТАБИРОВАНИЕ И АНАЛИЗ PCA")
    print("="*60)
    
    # Разделяем на X и y
    df_clean = df.copy()
    
    if target_col and target_col in df_clean.columns:
        y = df_clean[target_col]
        X = df_clean.drop(columns=[target_col])
    else:
        y = None
        X = df_clean.copy()
        
    # Работаем только с числовыми признаками
    X_numeric = X.select_dtypes(include=[np.number])
    non_numeric_cols = X.select_dtypes(exclude=[np.number]).columns
    
    if len(non_numeric_cols) > 0:
        print(f"[INFO] Исключены из анализа нечисловые колонки: {list(non_numeric_cols)}")

    # ---------------------------------------------------------
    # 1. БОРЬБА С МУЛЬТИКОЛЛИНЕАРНОСТЬЮ
    # ---------------------------------------------------------
    print(f"\n[1] АНАЛИЗ КОРРЕЛЯЦИЙ (Порог > {corr_threshold})")
    
    corr_matrix = X_numeric.corr().abs()
    
    # Выделяем верхний треугольник матрицы корреляций
    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
    
    # Находим колонки, где корреляция выше порога
    to_drop = [column for column in upper.columns if any(upper[column] > corr_threshold)]
    
    print(f"  Исходное количество признаков: {X_numeric.shape[1]}")
    if to_drop:
        print(f"  Кандидаты на удаление (дублирование информации): {to_drop}")
        # Визуализация ДО (опционально, если не слишком много признаков)
        if X_numeric.shape[1] < 50:
            plt.figure(figsize=(10, 8))
            sns.heatmap(X_numeric.corr(), cmap='coolwarm', annot=False)
            plt.title("Матрица корреляций (До очистки)")
            plt.show()
            
        X_reduced = X_numeric.drop(columns=to_drop)
        print(f"  -> Удалено признаков: {len(to_drop)}")
    else:
        print("  Высококоррелированных признаков не найдено.")
        X_reduced = X_numeric

    print(f"  Осталось признаков: {X_reduced.shape[1]}")

    # ---------------------------------------------------------
    # 2. МАСШТАБИРОВАНИЕ (ROBUST SCALER)
    # ---------------------------------------------------------
    print(f"\n[2] МАСШТАБИРОВАНИЕ (RobustScaler)")
    # RobustScaler использует медиану и IQR, устойчив к оставшимся микро-выбросам
    scaler = RobustScaler()
    X_scaled_array = scaler.fit_transform(X_reduced)
    X_scaled = pd.DataFrame(X_scaled_array, columns=X_reduced.columns, index=X_reduced.index)
    
    print("  Данные приведены к единому масштабу (Median=0, IQR=1).")

    # ---------------------------------------------------------
    # 3. АНАЛИЗ PCA (ИССЛЕДОВАНИЕ)
    # ---------------------------------------------------------
    print(f"\n[3] АНАЛИЗ ГЛАВНЫХ КОМПОНЕНТ (PCA Check)")
    
    pca = PCA()
    pca.fit(X_scaled)
    
    # Считаем накопленную дисперсию
    cumulative_variance = np.cumsum(pca.explained_variance_ratio_)
    n_components_95 = np.argmax(cumulative_variance >= 0.95) + 1
    
    print(f"  Количество компонент для объяснения 95% дисперсии: {n_components_95} из {X_scaled.shape[1]}")
    
    # Визуализация "Метод локтя"
    plt.figure(figsize=(8, 4))
    plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='--')
    plt.axhline(y=0.95, color='r', linestyle='-', label='95% threshold')
    plt.xlabel('Количество компонент')
    plt.ylabel('Накопленная дисперсия')
    plt.title('PCA: Объясненная дисперсия')
    plt.legend()
    plt.grid(True)
    plt.show()
    
    # Проверка корреляции с таргетом (если он есть)
    if y is not None:
        # Создаем временный датасет с компонентами
        pca_transformed = pca.transform(X_scaled)
        # Берем столько компонент, сколько нужно для 95%
        pca_cols = [f'PC{i+1}' for i in range(n_components_95)]
        df_pca = pd.DataFrame(pca_transformed[:, :n_components_95], columns=pca_cols, index=X_scaled.index)
        
        # Считаем корреляцию компонент с целевой переменной
        correlations = df_pca.corrwith(y).abs().sort_values(ascending=False)
        print("  Корреляция Топ-3 главных компонент с целевой переменной:")
        print(correlations.head(3))
        
        if correlations.max() < 0.2:
            print("  [ВЫВОД] Корреляция компонент с таргетом низкая. \n"
                  "  -> Рекомендуется использовать отобранные исходные признаки (X_scaled), а не PCA.")
        else:
            print("  [ВЫВОД] Найдена значимая связь компонент с таргетом. \n"
                  "  -> Можно попробовать обучить модель на PCA-признаках.")
    
    # ---------------------------------------------------------
    # СБОРКА РЕЗУЛЬТАТА
    # ---------------------------------------------------------
    # Возвращаем X_scaled (отобранные исходные признаки) + y. 
    # Если вы решите использовать PCA, это делается отдельным шагом, 
    # но обычно "чистые" признаки интерпретируемее.
    
    if y is not None:
        df_final = X_scaled.join(y)
        # Если были нечисловые колонки, возвращаем их тоже (но они не масштабированы!)
        if len(non_numeric_cols) > 0:
            df_final = df_final.join(X[non_numeric_cols])
    else:
        df_final = X_scaled
        
    print("\n" + "="*60)
    return df_final

# --- ПРИМЕР ИСПОЛЬЗОВАНИЯ ---
# df_ready_for_ml = perform_feature_selection_and_scaling(
#     df_clean_no_outliers, 
#     target_col='Гармония Бессмертия', 
#     corr_threshold=0.9
# )